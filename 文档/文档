# 数智最终考核-文本分类

## 准备阶段

### 概念

#### 1.文本分类

概念：文本分类是自然语言处理的一个基本任务，试图推断出给定的文本（句子、文档等）的标签或标签集合。它根据一个已经被标注的训练文档集合, 找到文档特征和文档类别之间的关系模型, 然后利用这种学习得到的关系模型对 新的文档进行类别判断 。

过程：文本分类一般包括了文本的表达、 分类器的选择与训练、 分类结果的评价与反馈等过程，其中文本的表达又可细分为文本[预处理](https://so.csdn.net/so/search?q=预处理&spm=1001.2101.3001.7020)、索引和统计、特征抽取等步骤。文本分类系统的总体功能模块为：
（1） 预处理：将原始语料格式化为同一格式，便于后续的统一处理；
（2） 索引：将文档分解为基本处理单元，同时降低后续处理的开销；
（3） 统计：词频统计，项（单词、概念）与分类的相关概率；
（4） 特征抽取：从文档中抽取出反映文档主题的特征；
（5）分类器：分类器的训练；
（6） 评价：分类器的测试结果分析。

#### 2.keras

中文文档：[主页 - Keras 中文文档 (keras-zh.readthedocs.io)](https://keras-zh.readthedocs.io/)

Keras是一个极简的、高度模块化的神经网络库，采用Python（**Python 2.7-3.5**.）开发，能够运行在[TensorFlow](http://www.oschina.net/p/tensorflow)和[Theano](http://www.oschina.net/p/theano)任一平台，好项目旨在完成深度学习的快速开发。

特性：

- 可以快速简单的设计出原型（通过总模块化、极简性、和可扩展性）
- 同时支持卷积网络和循环网络，以及两者的组合
- 支持任意的连接方案(包括多输入和多输出）
- 支持GPU和CPU

## 实践阶段

### （一）数据预处理

#### 1.文本处理

（1）去除标点符号

（2）创建停词表

（3）分词

（4）转换成小写

（5）观察标签类型

![image-20220430125420662](C:\Users\于杨小仙女~\AppData\Roaming\Typora\typora-user-images\image-20220430125420662.png)

#### 2.文本转数据

texts_to_sequences(texts) 将多个文档转换为word下标的向量形式,shape为[len(texts)，len(text)] -- (文档数，每条文档的长度)

#### 3.词向量的训练

目标：都是得到词向量，使向量之间尽可能多的蕴含语义和语法的特点，词向量的训练很重要

##### 方法一：word2vec

​	文档：[文本分类实战（一）—— word2vec预训练词向量 - 微笑sun - 博客园 (cnblogs.com)](https://www.cnblogs.com/jiangxinyang/p/10207273.html)

​	Word2vec，是用来产生词向量的相关模型。是浅层的神经网络，用来训练以重新构架文本。训练完成之后，word2vec模型可用来映射每个词到一个向量，可用来表示词对词之间的关系，该向量为神经网络之隐藏层。Word2Vec主要依赖单词的上下文来衡量单词的含义。

![img](http://gavinhuang.github.io/images/imgs/20171127-155555.png)

​		

神经网络的主要思路是：首先将目标单词做为 “one-hot”向量的形式输入；然后通过一层隐藏层，我们试图训练神经网络以达到提升上下文相关词的概率，而降低非上下文相关词（即从未出现在目标词周围的词）的概率。这需要在输出层中引入一个softmax函数。一旦训练完毕，输出层被丢弃而我们所需要的就只是隐藏层的权重。 Word2Vec有两种形式：skip-gram和CBOW。前者已知目标词来预测上下文词，而后者则用上下文词来预测目标单词。

![img](https://img-blog.csdn.net/20160531195447467?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

尝试：

​		在调用相关函数的时候有很多参数，为了寻找表现做好的参数，调参耗费较长的时间，

##### 		方法二：Glove

[(68条消息) 理解GloVe模型（+总结）_AI蜗牛之家的博客-CSDN博客_glove模型](https://zsweety.blog.csdn.net/article/details/79642083?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-1.pc_relevant_aa&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-1.pc_relevant_aa&utm_relevant_index=2)

​	首先基于语料库构建词的共现矩阵，然后基于共现矩阵和GloVe模型学习词向量。一种是由Word2Vec的skip-gram算法改进而来。GloVe词向量的训练，是直接面对Xij，即共现矩阵，进行优化的。也就是它是直接朝着全局的统计信息进行训练优化的。能够更加充分的利用统计信息，实际的语料很稀疏，但是通过GloVe可以降低语料的复杂程度，使数据变得更加的有效。

损失函数为：![image-20220430092357424](C:\Users\于杨小仙女~\AppData\Roaming\Typora\typora-user-images\image-20220430092357424.png)

1.f(0)=0，也就是说如果两个词如果没有共同出现过，权重就是0。
2.f ( x ) f(x)f(x)应该是非递减函数，所以经常出现的单词权重要大于很少一起出现的单词。
3.f ( x ) f(x)f(x)对于较大的x xx不能取太大的值，所以一些经常出现的词权重不会太大，比如一些停止词。



理解：GloVE与Word2vec区别，前者是从全局考虑多个窗口进行更新，后者是每次用局部信息更新词向量。

#### 4.补充

关于停用词：用来提升文本特征的质量，或者降低文本特征的维度。在不同的任务中，一些词语无法提供有价值的信息，那么该类词就可以忽略。停用词就是一些高频出现但是并不重要的词语。

关于TF-IDF：在生成文本的过程中，假设一个词语i出现的概率为
$$
p_i
$$
词语带来的不确定性期望值就是：
$$
p_ilog(1/p_i)
$$
——这个指标即Term Frequency-Inverse Document Frecuency。TF-IDF值非常低的几个词找出来后就是一个初步的停词表了

### （二）模型搭建

#### 1.TextCNN

在卷积神经网络中，卷积核的尺寸远远小于输入层的维度，这样每一次的输出值都是只与样本的特定部位部分产生联系--稀疏交互。意义在于不需要识别样本所有的特征，只需要在卷积核移动的时候，样本中有特征符合即可，才能将局部的样本特征组合起来形成更加复杂抽象的特征最终实现识别分类等任务。每一个卷积核都对应了一组参数，在不同的位置使用的都是相同的参数实现参数共享，这使得卷积的运算效率更高。

![image-20220430113847374](C:\Users\于杨小仙女~\AppData\Roaming\Typora\typora-user-images\image-20220430113847374.png)

![img](https://img-blog.csdnimg.cn/20200731215121326.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIyNDQxMTUx,size_16,color_FFFFFF,t_70#pic_center)

通过一维的卷积层实现特征点的提取，我采用三个窗口不同（3,4,5）的卷积核进行操作，接着采用最大池化层，然后将三个窗口的输出都拼接到一起，用flatten进行降维，添加Dropout层去除几个神经节点，防止过拟合，最后全连接层通过softmax实现多分类。

模型图：

![image-20220430115944354](C:\Users\于杨小仙女~\AppData\Roaming\Typora\typora-user-images\image-20220430115944354.png)

| epoch | loss   | accuracy |
| ----- | ------ | -------- |
| 50    | 1.3061 | 0.4544   |
| 100   | 0.9752 | 0.6398   |
| 150   | 0.7148 | 0.7503   |
| 200   | 0.5878 | 0.8003   |
| 500   | 0.3336 | 0.8681   |
| 600   | 0.2996 | 0.8744   |
| 700   | 0.2849 | 0.8783   |

可以看出来随着迭代次数的增加，损失值一直在下降和准确率一直在上高，但是TextCNN模型再kaggle的评分最高实在epoch=600的时候，再超过时应该是出现了过拟合现象。我又尝试着在模型中再多加入一层全连接层，并且也加入了dropout层想要实现特征的有效提取与映射，但是效果并不理想。

#### 2.RNN

尝试了简单的RNN模型但是当实验后我就放弃了这个模型去寻找表现更好的模型。epoch仅50次损失值就可以降到0.06这样的小的数值，过拟合现象太严重。

模型图：

![image-20220430140348149](C:\Users\于杨小仙女~\AppData\Roaming\Typora\typora-user-images\image-20220430140348149.png)

#### 3.LSTM

当尝试过TextCNN后，发现效果并不佳，我又开始寻找新的更加复杂的模型以求能达到更好的表现效果。

不同于CNN在空间上提取文本特征的方式，LSTM是在时间上提取文本的特征。是一种特殊的RNN，主要为了解决长序列训练过程中的梯度消失和梯度爆炸问题。简单来说，就是相比普通的RNN，LSTM能够在更长的序列中有更好的表现。通过对细胞状态中信息遗忘和记忆新的信息使得对后续时刻计算有用的信息得以传递，而无用的信息被丢弃，并且在每个时间步都会输出新的状态，其中信息的记忆与遗忘是通过上个时刻的隐层状态和该时刻的参数控制的。

![在这里插入图片描述](https://img-blog.csdnimg.cn/a4b6b43e4f6649fca4d4790ed55bfbb2.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAeWFuZ2xlZTA=,size_20,color_FFFFFF,t_70,g_se,x_16)

![img](https://img-blog.csdn.net/20180711103357715?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hzY19j/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

LSTM实现了不再是像RNN那样简单的运算，而是时间也能横向更新新的参数以实现更好的表现效果。因为模型学习能力太强所以在模型中我使用了两次的Dropout层去防止过拟合情况。

模型图：

![image-20220430131225600](C:\Users\于杨小仙女~\AppData\Roaming\Typora\typora-user-images\image-20220430131225600.png)



| epoch | loss   | accuracy |
| ----- | ------ | -------- |
| 50    | 0.4781 | 0.8751   |
| 100   | 0.3637 | 0.8468   |

当epoch为50时，已经取得了这个模型的最高分，当100时又出现了过拟合的情况。在使用LSTM模型时候，通过画出模型的损失值和准确值的图像，

![image-20220427004044598](C:\Users\于杨小仙女~\AppData\Roaming\Typora\typora-user-images\image-20220427004044598.png)

![image-20220427011032463](C:\Users\于杨小仙女~\AppData\Roaming\Typora\typora-user-images\image-20220427011032463.png)

我发现两者的波动值都特别的大，无论迭代的次数的多少，这两个指标的波动都特别的大。猜想应该是每一次梯度下降的方向都不同，差别才这么大。

#### 4.BI-LSTM

尝试过LSTM后，考虑到LSTM无法实现对整个句子全面的理解，我又尝试了Bi-LSTM模型。通过该模型能更好的实现捕捉双向的语义，能够对整个句子的句意有更加深刻的认识。反向的LSTM可以看成是两层复杂的神经网络，一层是从句子的开头开始输入，而第二层则是从右边作为输入的起点，两者从同一个文本的不同方向进行相同的运算过程，最后将两层的结果再进行新的处理，最后达到分类的结果

![img](https://img2018.cnblogs.com/blog/1241834/201903/1241834-20190304202026074-2036551509.png)

在上个LSTM模型中，就发现过拟合现象比较严重，所以在这个模型中我在Embedding 层的后面就加入了Dropout层来希望降低模型的强学习能力。

![image-20220430134828695](C:\Users\于杨小仙女~\AppData\Roaming\Typora\typora-user-images\image-20220430134828695.png)

| epoch | loss   | accuracy |
| ----- | ------ | -------- |
| 50    | 0.3640 | 0.8846   |
| 100   | 0.0930 | 0.9826   |
| 200   | 0.0172 | 0.9971   |
|       |        |          |

### （三）模型评估

（1）画出模型图

（2）损失值和准确率的可视化

### （四）GUI实现

通过调用tkinter库以实现效果，还没有成功

### （五）总结

我首先采用的模型是Textcnn模型，并在这个模型上耗费很多时间，但是从现在的实验结果来看，该模型在这次的任务中表现的并不是特别的好，在epoch为600时才达到了最佳，而且速度也比较慢，整体来说效率并不是很高。我现在在kaggle中评分最高所用的模型是LSTM，相对比之下在五十次的时候就达到了最佳。通过这次任务的训练，我认识到了调参的重要性，这个过程中同一个模型在不同的参数之下都会表现出差别很大的结果，好的合适的参数才能使得模型表现出最好的效果。我认为我在这次的任务中还是没有找到参数的最佳搭配，还需要更多的调试。

已经到了考核最后，这个总结也算是告别我这两个月为了考核所作出的努力，不知道结果是什么样的，但是这两个月来，我想我真的学到了很多，不止是知识，也还有我对深度学习的兴趣吧，总会记得为他熬的夜，会记得为他掉的头发，会记得无从下手的慌张，总之，很感谢数智，让我的两个月过的很充实，很有挑战性，很有干劲儿！！！所以如果可以加入会更加努力的，如果不行也会在这个方向上继续努力的！
